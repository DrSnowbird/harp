
\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
% Computer Society journal (but not conference!) papers do something unusual
% with the very first section heading (almost always called "Introduction").
% They place it ABOVE the main text! IEEEtran.cls does not automatically do
% this for you, but you can achieve this effect with the provided
% \IEEEraisesectionheading{} command. Note the need to keep any \label that
% is to refer to the section immediately after \section in the above as
% \IEEEraisesectionheading puts \section within a raised box.




% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps (small caps for compsoc).
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)

\IEEEPARstart{G}{iven} two graphs $G$ and $H$, the subgraph isomorphism problem
asks if $H$ is isomorphic to a subgraph of $G$. The counting problem associated
with this seeks to count the number of copies of $H$ in $G$. These and other
variants are fundamental problems in Network Science and have a wide range of
applications in areas such as bioinformatics, social networks, semantic web,
transportation and public health.  Analysts in these areas search for meaningful
patterns in networked data; often, these patterns are specific subgraphs such as
trees.  Three different variants of subgraph analysis problems have been studied
extensively.  The first version involves counting specific subgraphs, which has
applications in bioinformatics~\cite{alon2008biomolecular,
huffner2008algorithm}.  The second involves finding the most frequent subgraphs
either in a single network or in a family of networks---this has been used in
finding patterns in bioinformatics (e.g.,~\cite{kuramochi2005finding}),
recommendation networks~\cite{leskovec2006patterns}, chemical structure
analysis~\cite{raymond2002maximum}, and detecting memory
leaks~\cite{maxwell2010diagnosing}. The third involves finding subgraphs which
are either over-represented or under-represented, compared to random networks
with similar properties---such subgraphs are referred to as ``motifs''. Milo et
al. ~\cite{milo2002network} identify motifs in many networks, such as
protein-protein interaction (PPI) networks, ecosystem food webs and neuronal
connectivity networks. Subgraph counts have also been used in characterizing
networks~\cite{przulj2007biological}.

Subgraph Isomorphism problem and its variants are well known to be
computationally challenging.  In general the decision version of the problem is
{\sf NP}-hard, and the counting problem is \#{\sf P}-hard.  Extensive work has
been done in theoretical computer science on this problem; we refer the reader
to the recent papers
by~\cite{marx2014everything,flum2004parameterized,curticapean2014complexity} for
an extensive discussion on the decision and counting complexity of the problem
and tractable results for various parameterized versions of the problem.

The primary focus of this paper is on the three mentioned variants of the
subgraph isomorphism problem when $k$, the number of nodes in the template $H$,
is fixed. Letting $n$ be the number of nodes in $G$, one can immediately get
simple algorithms with running time $O(n^k)$ to find and count the number of
copies of template $H$ in $G$. Note that in this paper we focus on non-induced
subgraph matching.
%These are computationally very challenging problems, and there has been a lot
%of work on finding a subgraph (also referred to as a ``template'') of size $k$
%in a graph with $n$ nodes.  Eisenbrand \emph{et al}.
%~\cite{eisenbrand2004complexity} developed an algorithm with a running time of
%roughly $O(n^{\omega k/3})$ (which improves on the naive $O(n^k)$ time
%algorithm), where $\omega$ denotes the exponent of the best possible matrix
%multiplication algorithm. If the template has an independent set of size $s$,
%Vassilevska \emph{et al}.  \cite{vassilevska2009finding} give an algorithm with
%an improved running time of $O(2^sn^{k-s+3}k^{O(1)})$; this is improved
%slightly by Kowaluk \emph{et al}.  \cite{kowaluk2011counting}. 
When the template is a tree or has a bounded treewidth, Alon \emph{et
al}.~\cite{alon2008biomolecular} present an elegant randomized approximation
algorithm with running time
$O(k|E|2^ke^k\log{(1/\delta)}\frac{1}{\varepsilon^2})$, where $\varepsilon$ and
$\delta$ are error and confidence parameters, respectively, based on the color
coding technique.  There result was  significantly improved by Koutis and
Williams~\cite{koutis2009limits} who gave an algorithm with running time of
$O(2^k|E|)$.

A lot of practical heuristics have also been developed for various versions of
these problems, especially for the frequent subgraph mining problem. An example
is the ``Apriori'' method, which uses a level-wise exploration of the template
\cite{inokuchi2000apriori, kuramochi2005finding}, for generating candidates for
subgraphs at each level; these have been made to run faster by better pruning
and exploration techniques, e.g.,~\cite{kuramochi2005finding, huan2004spin,
yan2005mining}. Other approaches in relational databases and data mining involve
queries for specific labeled subgraphs, and have combined relational database
techniques with careful depth-first exploration, e.g.,~\cite{sakr2009graphrel,
ronen2009evaluating, brocheler2010cosi}.

Most of these approaches are
sequential, and generally  scale to modest size graphs $G$  and templates $H$.
Parallelism is necessary to scale to much larger networks and templates.
In general, these approaches are  hard to parallelize as it is 
difficult to decompose the task into independent subtasks. It is not clear if
candidate generation approaches~\cite{kuramochi2005finding, huan2004spin,
yan2005mining} can be parallelized and scaled to large graphs and computing
clusters. Two recent approaches for parallel algorithms, related to this work,
are~\cite{brocheler2010cosi, zhao2010subgraph}. The approach of Br\"{o}cheler
\emph{et al}. ~\cite{brocheler2010cosi} requires a complex preprocessing and
enumeration process, which has high end-to-end time, while the approach of
\cite{zhao2010subgraph} involves an MPI-based implementation with a very high
communication overhead for larger templates.  Two other papers
\cite{suri2011counting, pagh2011colorful} develop MapReduce based algorithms for
approximately counting the number of triangles with a work complexity bound
$O(|E|)$. The development of  parallel algorithms for
subgraph analysis with rigorous polynomial work complexity, which are
implementable on heterogeneous computing resources remains an open problem.
Due to the complexity of
enumerating subgraphs, people propose to compute some metrics of the subgraph
which is anti-monotune to the subgraph size. The algorithm  reported in
\cite{abdelhamid2016scalemine} is capable of computing subgraph support on
 large network with up to 1 Billion edges. However, it requires each
machine to have a copy of the graph in memory which limits its scalability to larger graphs.
Additionally, computing support requires much less computational effort
than counting subgraphs. Another recent work also employs MapReduce to match
subgraph~\cite{suo2016towards} which scales to networks with up to 300 million
edges. 

Other approaches studied in the context of data mining and databases,
e.g.,~\cite{sakr2009graphrel, ronen2009evaluating, brocheler2010cosi},
are capable of processing large networks, but are usually slow due to
limitations of database techniques for processing networks.

\noindent
\textbf{Our contributions}.
In this paper, we present \sahad{}, a new algorithm for
\underline{S}ubgraph \underline{A}nalysis using \underline{Had}oop, with
rigorously provable polynomial work complexity for several variants of the subgraph
isomorphism problem when $H$ is a tree.
\sahad{} scales to very large graphs, and because of the Hadoop
implementation, runs flexibly on a variety of computing resources, including
Amazon EC2 cloud. Our specific contributions are discussed below.


%\begin{enumerate}
%\item

\smallskip
\textbf{1.} \sahad{} is the first MapReduce-based algorithm for finding and
counting labeled trees in very large networks.
The only prior Hadoop based approaches have been on triangles
\cite{tsourakakis2009doulion, pagh2011colorful, suri2011counting} in very large
networks, or more general subgraphs on relatively small networks
\cite{liu2009mapreduce}. Our main technical contribution is the development of a
Hadoop version of the \emph{color coding}
algorithm of Alon \emph{et al}.~\cite{alon2008biomolecular, alon1995color}, which
is a (sequential) randomized approximation algorithm for subgraph counting.
It is a randomized approximation algorithm that for any $\varepsilon, \delta$,
gives a $(1\pm\varepsilon)$ approximation to the number of embeddings with
probability at least $1-2\delta$.
We prove that the work complexity of \sahad{} is
$O(k|E_G|2^{2k}e^k\log{(1/\delta)}\frac{1}{\varepsilon^2})$, which is more than
the running time of the sequential algorithm of~\cite{alon2008biomolecular}
by just a factor of $2^k$.
%\item

\iffalse
%%%%%%%%%
One of the main challenges for parallel algorithms is that only a part of the
graph can be stored in memory if it is very large. Most real networks are characterized
by small diameter and high expansion, so that even storing the $d$-neighborhood
of a node  $v$ (consisting of nodes within distance $d$ of $v$) is infeasible.
This makes searching for subgraphs with diameter more than $d$ very challenging,
since an embedding might be split across partitions. Our approach based on
color-coding solves this ingeniously by considering ``colorful'' embeddings,
as discussed in Section~\ref{sec:intro-color-coding}.
%%%%%%%%
\fi

\smallskip
\textbf{2.} We demonstrate our results on instances generated using the Erd\"{o}s-Renyi
random graph model, the Chung-Lu random graph model
and on synthetic social contact graphs for Miami city and Chicago city
(with 52.7 and 268.9 million edges, respectively), constructed using
the methodology of~\cite{barrett2009generation}. We study the performance of
counting unlabeled/labeled templates with up to 12 nodes. The total running
times for templates with 12 nodes on Miami and Chicago networks are 15 and 35
minutes, respectively; note that these are the \emph{total end-to-end} times,
and do not require any additional pre-processing (unlike, e.g.
\cite{brocheler2010cosi}).


\smallskip
\textbf{3.} We discuss how our basic algorithms for counting subgraphs can
be extended to compute supervised motifs and graphlet frequency distributions.
They can also be extended to count labeled subgraphs.

\smallskip
\textbf{4.} \sahad{} runs easily on heterogeneous computing resources, e.g., it
scales well when we request up to $16$ nodes on a medium size cluster with $32$
cores per node. Our Hadoop based implementation is also amenable to running on
public clouds, e.g., Amazon EC2~\cite{Web:Amazon-EC2}. Except for a 10-node
template which produces extremely large amount of data so as to incur the I/O
bottle neck on the virtual disk of EC2, the performance of \sahad{} on
EC2 is almost the same as on the local cluster. This would enable researchers
to perform useful queries even if they do not have access to large resources,
such as those required to run previously proposed querying infrastructures. We
believe this aspect is unique to \sahad{} and lowers the barrier-to-entry
for scientific researchers to utilize advanced computing resources.

\smallskip
\textbf{5.}  We study the performance improvement in extensions of the standard
Hadoop framework. The enhanced algorithm is called \ensahad{}.
First, we consider techniques to explicitly
control the sorting and inter partition communications in Hadoop. We find
that reducing the sorting step by pre-allocating can improve the
performance by about 20\%, but improved partitioning does not seem to help.


\smallskip
\textbf{6.} Finally, we implement \sahad{} within the Harp~\cite{qiu2014towards} framework
-- the new algorithm is called \harpsahad{}.  \harpsahad{}
yields an order of magnitude improvement in performance, as a result of
its flexibility in task scheduling, data flow control and in memory cache. We
are able to scale to networks with up to hundreds of millions of edges using the
\harpsahad{} 
with unlabeled templates with 7 nodes. 




%%%%%%%%%%%%%%%%
%a parallel algorithm \sahad{} for subgraph
%counting based on MapReduce and color coding. We derive the MapReduce form of
%the color coding algorithm and give bounds on computational cost. \sahad{} 
%can be deployed in modern cloud computing environment with
%minimum effort. We also study the performance improvement when we explictly
%control the sorting and inter partition communications in \sahad{}. Then
%we implement our algorithm within the Harp~\cite{qiu2014towards} framework which
%overcome \sahad{} by an order of magnitude in terms of performance, due to
%its flexibility in task scheduling, data flow control and in memory cache. We
%are able to scale to networks with upto hundreds of millions of edges using the Harp
%implementation with fairly large unlabeled templates with 7 nodes. Note that
%the unlabled subgraph matchings have much more occurrences than labeled subgraph
%matchings which is the topic of most of the other works. Also the Harp implementation 
%achieves an order of magnitude performance improvement over \sahad{}.  

\noindent
\textbf{Organization}.
Section~\ref{sec:background} introduces the background for the subgraph counting
problem and MapReduce, the open-sourced implementation Hadoop and the Harp
system. Then in Section~\ref{sec:sequential}, we give a brief overview of the
color coding algorithm proposed by Alon \emph{et. al} in
\cite{alon2008biomolecular}. Then in Section~\ref{sec:parallel} we present our
MapReduce implementations. In Section~\ref{sec:performance-analysis} we study
the computation cost of our algorithm. Section~\ref{sec:apps} proposes several
variations of the subgraph counting problems that can be computed using our
framework. Section~\ref{sec:experiment} discusses experiment results of
\sahad{}, \ensahad{} and \harpsahad{}. Finally, Section~\ref{conclusion}
concludes the paper.

\noindent
\textbf{Extension from conference version.} The \sahad{} algorithm appeared in 
\cite{zhao2012sahad}. The results on \ensahad{} and \harpsahad{} are new additions.
Since the publication of \cite{zhao2012sahad}, there has been more work on
parallelizing the color coding technique, e.g., \cite{slota2013fast, slota2015parallel}.
However, none of these have been based on MapReduce and its generalizations.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.
% However, the Computer Society has been known to put floats at the bottom.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.
